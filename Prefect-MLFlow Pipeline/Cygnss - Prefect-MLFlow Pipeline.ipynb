{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect import task, Flow\n",
    "from datetime import timedelta\n",
    "from prefect.schedules import IntervalSchedule\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from prefect import task, Flow, Parameter, Client\n",
    "from prefect.run_configs import KubernetesRun\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from prefect.storage import S3\n",
    "from prefect.tasks.control_flow import merge\n",
    "from prefect import task, Flow, case\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import requests\n",
    "from typing import Tuple\n",
    "import logging\n",
    "import h5py\n",
    "import sqlite3\n",
    "import time\n",
    "#import libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import json\n",
    "import datetime\n",
    "import streamlit as st\n",
    "from pymongo import MongoClient, errors\n",
    "from PIL import Image \n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8caf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_rmse():\n",
    "    \n",
    "    filename = \"best_predictions.h5\"\n",
    "\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        # Print all root level object names (aka keys) \n",
    "        # these can be group or dataset names \n",
    "        print(\"Keys: %s\" % f.keys())\n",
    "        # get first object name/key; may or may NOT be a group\n",
    "        a_group_key = list(f.keys())[0]\n",
    "\n",
    "        # get the object type for a_group_key: usually group or dataset\n",
    "        print(type(f[a_group_key])) \n",
    "\n",
    "        # If a_group_key is a group name, \n",
    "        # this gets the object names in the group and returns as a list\n",
    "        data = list(f[a_group_key])\n",
    "\n",
    "        # If a_group_key is a dataset name, \n",
    "        # this gets the dataset values and returns as a list\n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "        \n",
    "        # Use True lable to calculate RMSE\n",
    "        return 0.7\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7224161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(max_retries=3, retry_delay=timedelta(seconds=10))\n",
    "def is_model_degraded_condition():\n",
    "    rmse = calculate_rmse()\n",
    "    if rmse > 0.4:\n",
    "        return True\n",
    "    else:\n",
    "        return False  \n",
    "\n",
    "    \n",
    "@task(max_retries=3, retry_delay=timedelta(seconds=10))\n",
    "def inference():\n",
    "    os.system(\"sbatch ./../../inference_harsh_cp_1.sh\")    \n",
    "    time.sleep(30)\n",
    "    \n",
    "@task(max_retries=3, retry_delay=timedelta(seconds=10))\n",
    "def save_to_database():\n",
    "    pass\n",
    "\n",
    "@task(max_retries=3, retry_delay=timedelta(seconds=10))\n",
    "@st.experimental_singleton\n",
    "def init_connection(): \n",
    "        client = MongoClient(host='localhost:27017' , serverselectiontimeoutms=3000)\n",
    "        return client\n",
    "    \n",
    "@task(max_retries=3, retry_delay=timedelta(seconds=10))\n",
    "def write_data(client):\n",
    "        data_1 = {\n",
    "        \"rmse\": 3.1, \n",
    "        \"event_date\":  datetime.datetime(2022, 8, 10),\n",
    "        \"image_url\": \"https://www.dkrz.de/en/about-en/aufgaben/dkrz-and-climate-research/@@images/image/large\"\n",
    "        }\n",
    "\n",
    "        data_2 = {\n",
    "        \"rmse\": 2.1,         \n",
    "        \"event_date\":  datetime.datetime(2022, 8, 9),\n",
    "        \"image_url\": \"https://www.dkrz.de/en/about-en/aufgaben/dkrz-and-climate-research/@@images/image/large\"\n",
    "        }\n",
    "\n",
    "        data_3 = {\n",
    "        \"rmse\": 3.2,         \n",
    "        \"event_date\":  datetime.datetime(2022, 8, 8),\n",
    "        \"image_url\": \"https://www.dkrz.de/en/about-en/aufgaben/dkrz-and-climate-research/@@images/image/large\"\n",
    "        }\n",
    "\n",
    "\n",
    "        cygnss_collection = client[\"cygnss\"].cygnss_collection\n",
    "\n",
    "        cygnss_collection = cygnss_collection.insert_many([data_1, data_2, data_3])\n",
    "\n",
    "        print(f\"Multiple tutorials: {cygnss_collection.inserted_ids}\")\n",
    "\n",
    "@task\n",
    "def get_data(client):        \n",
    "        cygnss = client.cygnss                        \n",
    "        items = cygnss.cygnss_collection.find()        \n",
    "        items = list(items)  # make hashable for st.experimental_memo\n",
    "        for item in items:\n",
    "            print(f\"RMSE is: {item['rmse']}\")            \n",
    "        \n",
    "        \n",
    "@task\n",
    "def drop_database(client):\n",
    "    client.drop_database('cygnss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e48e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.FlowRunner | Beginning Flow run for 'MLOps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.523 Beginning Flow run for 'MLOps'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'init_connection': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.543 Task 'init_connection': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'init_connection': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.547 Task 'init_connection': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'drop_database': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.554 Task 'drop_database': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'drop_database': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.559 Task 'drop_database': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'is_model_degraded_condition': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.566 Task 'is_model_degraded_condition': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['y_pred']>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'is_model_degraded_condition': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.631 Task 'is_model_degraded_condition': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:12+0200] INFO - prefect.TaskRunner | Task 'inference': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:12.638 Task 'inference': Starting task run...\n",
      "sh: 1: sbatch: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:42+0200] INFO - prefect.TaskRunner | Task 'inference': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:42.675 Task 'inference': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:42+0200] INFO - prefect.TaskRunner | Task 'case(True)': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:42.704 Task 'case(True)': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:42+0200] INFO - prefect.TaskRunner | Task 'case(True)': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:42.711 Task 'case(True)': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:42+0200] INFO - prefect.TaskRunner | Task 'write_data': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:42.720 Task 'write_data': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple tutorials: [ObjectId('630f310e0e226a62e1eb5a5b'), ObjectId('630f310e0e226a62e1eb5a5c'), ObjectId('630f310e0e226a62e1eb5a5d')]\n",
      "[2022-08-31 11:59:42+0200] INFO - prefect.TaskRunner | Task 'write_data': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:42.738 Task 'write_data': Finished task run for task with final state: 'Success'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-31 11:59:42+0200] INFO - prefect.TaskRunner | Task 'inference': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 11:59:42.745 Task 'inference': Starting task run...\n",
      "sh: 1: sbatch: not found\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schedule = IntervalSchedule(interval=timedelta(minutes=2))\n",
    "\n",
    "\n",
    "# 1. Get fresh data\n",
    "# 2. Pre-process the data\n",
    "# 3. Do a inference with that\n",
    "# 4. If model is working above a set threshold. Fine. \n",
    "# 5. If not, then train the model on new data.\n",
    "# 6. Evaluate the model and check if it is still fine or not and take specific action\n",
    "\n",
    "# TODO:\n",
    "# in case of failure of any task, retry \n",
    "# save the results in database\n",
    "\n",
    "with Flow(\"MLOps\") as flow:\n",
    "    \n",
    "    # download_data()\n",
    "    # pre_process()\n",
    "    \n",
    "    \n",
    "    client = init_connection()    \n",
    "    drop_database(client)\n",
    "    \n",
    "    inference()\n",
    "    \n",
    "    # read the results and tell if the model is degraded\n",
    "    is_model_degraded = is_model_degraded_condition()\n",
    "\n",
    "    # train on new data if error is more than threshold and log the results on test data\n",
    "    with case(is_model_degraded, True): \n",
    "#         model = train_model_task(train_data)        \n",
    "        inference()\n",
    "        is_model_degraded_condition()\n",
    "\n",
    "    # save_to_db\n",
    "    write_data(client)\n",
    "    \n",
    "#     get_data(client)\n",
    "    \n",
    "    \n",
    "    \n",
    "state = flow.run()\n",
    "print('DONE')\n",
    "# flow.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80215649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3f23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
