{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect import task, Flow\n",
    "from datetime import timedelta\n",
    "from prefect.schedules import IntervalSchedule\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from prefect import task, Flow, Parameter, Client\n",
    "from prefect.run_configs import KubernetesRun\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from prefect.storage import S3\n",
    "from prefect.tasks.control_flow import merge\n",
    "from prefect import task, Flow, case\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import requests\n",
    "from typing import Tuple\n",
    "import logging\n",
    "import h5py\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8caf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_rmse():\n",
    "    \n",
    "    filename = \"best_predictions.h5\"\n",
    "\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        # Print all root level object names (aka keys) \n",
    "        # these can be group or dataset names \n",
    "        print(\"Keys: %s\" % f.keys())\n",
    "        # get first object name/key; may or may NOT be a group\n",
    "        a_group_key = list(f.keys())[0]\n",
    "\n",
    "        # get the object type for a_group_key: usually group or dataset\n",
    "        print(type(f[a_group_key])) \n",
    "\n",
    "        # If a_group_key is a group name, \n",
    "        # this gets the object names in the group and returns as a list\n",
    "        data = list(f[a_group_key])\n",
    "\n",
    "        # If a_group_key is a dataset name, \n",
    "        # this gets the dataset values and returns as a list\n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "        \n",
    "        # Use True lable to calculate RMSE\n",
    "        return 0.7\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7224161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def is_model_degraded_condition():\n",
    "    rmse = calculate_rmse()\n",
    "    if rmse > 0.4:\n",
    "        return True\n",
    "    else:\n",
    "        return False  \n",
    "\n",
    "    \n",
    "@task\n",
    "def inference():\n",
    "    os.system(\"sbatch ./../../inference_harsh_cp_1.sh\")    \n",
    "    time.sleep(30)\n",
    "    \n",
    "@task\n",
    "def save_to_database():\n",
    "    pass\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e48e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-25 13:21:06+0200] INFO - prefect.FlowRunner | Beginning Flow run for 'MLOps'\n",
      "[2022-08-25 13:21:06+0200] INFO - prefect.TaskRunner | Task 'inference': Starting task run...\n",
      "[2022-08-25 13:21:37+0200] INFO - prefect.TaskRunner | Task 'inference': Finished task run for task with final state: 'Success'\n",
      "[2022-08-25 13:21:37+0200] INFO - prefect.TaskRunner | Task 'is_model_degraded_condition': Starting task run...\n",
      "Keys: <KeysViewHDF5 ['y_pred']>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "[2022-08-25 13:21:37+0200] INFO - prefect.TaskRunner | Task 'is_model_degraded_condition': Finished task run for task with final state: 'Success'\n",
      "[2022-08-25 13:21:37+0200] INFO - prefect.TaskRunner | Task 'case(True)': Starting task run...\n",
      "[2022-08-25 13:21:37+0200] INFO - prefect.TaskRunner | Task 'case(True)': Finished task run for task with final state: 'Success'\n",
      "[2022-08-25 13:21:37+0200] INFO - prefect.TaskRunner | Task 'inference': Starting task run...\n",
      "[2022-08-25 13:22:07+0200] INFO - prefect.TaskRunner | Task 'inference': Finished task run for task with final state: 'Success'\n",
      "[2022-08-25 13:22:07+0200] INFO - prefect.TaskRunner | Task 'is_model_degraded_condition': Starting task run...\n",
      "Keys: <KeysViewHDF5 ['y_pred']>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "[2022-08-25 13:22:07+0200] INFO - prefect.TaskRunner | Task 'is_model_degraded_condition': Finished task run for task with final state: 'Success'\n",
      "[2022-08-25 13:22:07+0200] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "schedule = IntervalSchedule(interval=timedelta(minutes=2))\n",
    "\n",
    "\n",
    "# 1. Get fresh data\n",
    "# 2. Pre-process the data\n",
    "# 3. Do a inference with that\n",
    "# 4. If model is working above a set threshold. Fine. \n",
    "# 5. If not, then train the model on new data.\n",
    "# 6. Evaluate the model and check if it is still fine or not and take specific action\n",
    "\n",
    "# TODO:\n",
    "# in case of failure of any task, retry \n",
    "# save the results in database\n",
    "\n",
    "with Flow(\"MLOps\", schedule=schedule) as flow:\n",
    "    \n",
    "    # download_data()\n",
    "    # pre_process()\n",
    "    \n",
    "    inference()\n",
    "    \n",
    "    \n",
    "    # read the results and tell if the model is degraded\n",
    "    is_model_degraded = is_model_degraded_condition()\n",
    "\n",
    "    # train on new data if error is more than threshold and log the results on test data\n",
    "    with case(is_model_degraded, True): \n",
    "#         model = train_model_task(train_data)        \n",
    "        inference()\n",
    "        is_model_degraded_condition()\n",
    "\n",
    "    # save_to_db()\n",
    "    \n",
    "state = flow.run()\n",
    "print('DONE')\n",
    "# flow.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
